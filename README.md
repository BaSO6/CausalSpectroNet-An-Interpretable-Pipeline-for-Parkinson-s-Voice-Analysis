# ğŸ™ï¸ CausalSpectroNet: An Interpretable Pipeline for Parkinsonâ€™s Voice Analysis

This repository implements a complete, languageâ€‘independent workflow for **Parkinsonâ€™s Disease (PD) voice classification** and **acoustic interpretability**. We fuse spectrogramâ€‘based causal modeling with symbolic acoustic tokens (via [WavTokenizer](https://github.com/xiaolaohu05/WavTokenizer)) to:

1. **Classify** HC vs. PD from speech
2. **Localize** discriminative timeâ€“frequency regions via Gradâ€‘CAM  
3. **Extract** symbolic â€œacoustic tokensâ€ and quantify their divergence  
4. **Reconstruct** listenable PDâ€‘specific audio from masked spectrograms  

Unfortunately, I can't provide the raw database here due to copyrights, and the processed data was too large for Github to hold. Therefore, I strongly advice users to look up the database on the Internet and save them in a folder called 'Voice". Then run audio_preprocessing_pipeline.py. Please make sure those spectrograms are saved in the same level of the database folder, adding '_Output' at the end of the folder name.
---

## ğŸš€ Quick Start

1. **Clone this repo**  
   ```bash
   git clone https://your.repo.url/Parkinson.git
   cd Parkinson
   ```

2. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   # e.g. librosa, soundfile, torch, torchvision, transformers, scikit-learn, opencv-python, tqdm
   ```

3. **Prepare data**  
   - Place raw `.wav` files under `Voice/`.  
   - Directory structure will be created automatically:  
     ```
     Voice/
       â”œâ”€â”€ China_HC/â€¦ .wav
       â””â”€â”€ China_PD/â€¦ .wav
     ```

4. **Run the full pipeline** (or invoke individual steps)  
   ```bash
   bash sleep_then_visualize.sh
   ```

---

## ğŸ—‚ï¸ Directory Structure

```
.
â”œâ”€â”€ audio_preprocessing_pipeline.py     # 1. WAV â†’ 1Â s segments + STFT/Mel/CQT PNG & metadata
â”œâ”€â”€ batch_gradcam_and_topk.py           # Batch GradCAM + Topâ€‘K spectrogram pairing
â”œâ”€â”€ batch_gradcam_spectro_*.py          # Perâ€‘variant GradCAM (ConstantQ / GlobalLocal / CausalAtt / Scalogram)
â”œâ”€â”€ generate_discriminative_audio.py    # Spectrogram â†’ masked spectrogram â†’ Griffinâ€‘Lim â†’ .wav
â”œâ”€â”€ gradcam_summary_figure.py           # Plot average HC/PD GradCAM for each spectrogram type
â”œâ”€â”€ gradcam_token_overlay_pipeline.py   # Overlay GradCAM + acousticâ€token heatmap on Topâ€‘K pairs
â”œâ”€â”€ run_all_experiments.py              # Orchestrates ablations, training, GradCAM, token analysis
â”œâ”€â”€ spectro_ablation_experiments.py     # Compare CausalAtt vs. ConstantQOnly vs. GlobalLocalOnly vs. ScalogramOnly
â”œâ”€â”€ spectro_ablation_experiments_single.py # Singleâ€‘variant ablation driver
â”œâ”€â”€ spectrogram_model_gradcam.py        # Helper: GradCAM on a single spectrogram image
â”œâ”€â”€ token_spectrogram_pipeline.py       # 2. Tokenize spectrograms via WavTokenizer â†’ `audio_token_results.csv`
â”œâ”€â”€ train_causal_spectro_model.py       # 3. Train CausalSpectroNet (globalâ€‘local perturbations + causal loss)
â”œâ”€â”€ token_model_extensions.py           # Helper extensions for acoustic token clustering & analysis
â”œâ”€â”€ token_model_training.py             # (Optional) Fineâ€‘tune or train your own WavTokenizer variant
â”œâ”€â”€ multi_modal_training.py             # (Optional) Train a joint audio + text (annotations) classifier
â”œâ”€â”€ run_all_experiments.py              # Topâ€‘level orchestration of all steps above
â”‚
â”œâ”€â”€ ablation/                           # Ablation scripts & configs
â”œâ”€â”€ figures/                            # Saved PNGs: spectrograms, GradCAM maps, overlays
â”œâ”€â”€ logs/                               # Training & experiment logs (seed0, etc.)
â”œâ”€â”€ models/                             # Model definitions & utilities
â”œâ”€â”€ result_data/                        # CSVs of results: `ablation_results_*.csv`, `token_topk_scores.csv`, â€¦
â”œâ”€â”€ saved_models/                       # Checkpoints: ConstantQOnly_seed0.pth, CausalAtt_seed0.pth, â€¦
â”œâ”€â”€ training/                           # Training pipelines for token & multimodal models
â”‚   â”œâ”€â”€ token_model_training.py
â”‚   â”œâ”€â”€ token_model_extensions.py
â”‚   â””â”€â”€ multi_modal_training.py
â”œâ”€â”€ Voice/                              # Input audio + autoâ€‘generated `*_Output/` directories
â”‚   â”œâ”€â”€ China_HC/
â”‚   â””â”€â”€ China_PD/
â””â”€â”€ spectrum.ipynb, Token.ipynb         # Exploratory notebooks (code snapshot)
```

---

## ğŸ”§ Stepâ€‘byâ€‘Step Workflow

### 1. Audio Preprocessing â†’ Spectrograms
```bash
python audio_preprocessing_pipeline.py
```
- Splits each `.wav` into 1Â s segments (silence removal via `librosa.effects.split`).  
- Generates **STFT**, **Mel**, **CQT** spectrograms (dB â†’ color PNG via Matplotlib).  
- Saves PNG and metadata `.json` under `Voice/..._Output/`.

### 2. Tokenization via WavTokenizer  
```bash
python token_spectrogram_pipeline.py
```
- **Refer to** [WavTokenizer](https://github.com/xiaolaohu05/WavTokenizer) for installing & configuring the tokenizer.  
- Takes spectrogram PNGs, extracts discrete tokens (e.g. 64â€‘codebook), outputs `audio_token_results.csv`.

### 3. Train CausalSpectroNet  
```bash
python train_causal_spectro_model.py
```
- **Globalâ€‘Local Transform**: FFTâ€mask + random erasing.  
- **CausalSpectroNet** (ResNet18 backbone):  
  - Dice loss for attentionâ€map consistency  
  - Symmetric KL loss for predictive consistency  
- Produces checkpoints in `saved_models/`.

### 4. Ablation Studies  
```bash
python spectro_ablation_experiments.py
```
- Compare four variants:  
  1. ConstantQOnly  
  2. GlobalLocalOnly  
  3. CausalAtt (full model)  
  4. ScalogramOnly  
- Outputs `ablation_results_*.csv` in `result_data/`.

### 5. GradCAM Visualizations  
#### a. Average Heatmaps  
```bash
python gradcam_summary_figure.py
```
- Computes & plots mean GradCAM over all HC vs. PD samples for each spectrogram type.

#### b. Topâ€‘K Pair Overlays  
```bash
python gradcam_token_overlay_pipeline.py
```
- Finds Topâ€‘K most divergent HC/PD spectrogram pairs.  
- Generates GradCAM + tokenâ€sequence overlay under `figures/gradcam_token_overlay/`.

### 6. Token Divergence Analysis  
```bash
python kl_js_token_analysis.py
```
- Reads `audio_token_results.csv`.  
- Computes **symmetric KL** & **Jensenâ€‘Shannon** divergence over codebook tokens.  
- Lists Topâ€‘K discriminative tokens and saves `token_topk_scores.csv`.

### 7. Discriminative Audio Reconstruction  
```bash
python generate_discriminative_audio.py
```
- Restores magnitude spectrogram from PNG, masks with GradCAM heatmap.  
- Inverts to waveform via Griffinâ€‘Lim â†’ `discriminative_pd.wav`, `discriminative_hc.wav`.  
- Playable in Jupyter / saved to disk.

---

## ğŸ“ˆ Results & Interpretation

- **Ablation**: Full CausalAtt model consistently outperforms singleâ€variant baselines.  
- **GradCAM**: PD samples show focused activations in lowâ€frequency tremor bands & phrase ends.  
- **Token KL**: Token IDs `3, 60, â€¦` exhibit highest KL divergence (PD vs. HC).  
- **Audio**: Reconstructed PD waveform highlights highâ€variance tremor frequencies.

---

## ğŸ¤ Acknowledgements & Citation

- **Gradâ€‘CAM**: *Selvaraju et al., ICCV 2017*.  
- **WavTokenizer**: *Ji et al., ICLR 2025*.  
- **Parkinsonâ€™s vocalization dataset**: *Apaydin et al.*  

